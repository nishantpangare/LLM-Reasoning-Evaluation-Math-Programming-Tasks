# LLM-Reasoning-Evaluation-Math-Programming-Tasks
This project implements and evaluates reasoning pipelines for Large Language Models (LLMs) on mathematics and programming tasks. The goal is to explore step-by-step reasoning, self-consistency, and error analysis for improving correctness and transparency of LLM outputs.
